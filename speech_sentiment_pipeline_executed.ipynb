{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a44348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "try:\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "except Exception as e:\n",
    "    PCA = None\n",
    "    TfidfVectorizer = None\n",
    "\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "def zcr(signal: np.ndarray) -> float:\n",
    "    return ((signal[:-1] * signal[1:]) < 0).mean()\n",
    "\n",
    "def rms_energy(signal: np.ndarray) -> float:\n",
    "    return np.sqrt(np.mean(signal**2) + 1e-12)\n",
    "\n",
    "def normalize_minmax(x: float, xmin: float, xmax: float) -> float:\n",
    "    if xmax - xmin < 1e-12:\n",
    "        return 0.5\n",
    "    return (x - xmin) / (xmax - xmin)\n",
    "\n",
    "@dataclass\n",
    "class AudioFeatureExtractor:\n",
    "    target_sr: int = 16000\n",
    "    nperseg: int = 512\n",
    "    noverlap: int = 256\n",
    "\n",
    "    def _resample(self, x: np.ndarray, sr: int) -> np.ndarray:\n",
    "        if sr == self.target_sr:\n",
    "            return x\n",
    "        t_old = np.linspace(0, len(x) / sr, num=len(x), endpoint=False)\n",
    "        t_new = np.linspace(0, len(x) / sr, num=int(len(x) * self.target_sr / sr), endpoint=False)\n",
    "        return np.interp(t_new, t_old, x).astype(np.float32)\n",
    "\n",
    "    def compute_spectrogram(self, x: np.ndarray, sr: int) -> np.ndarray:\n",
    "        x = self._resample(x, sr)\n",
    "        freqs, times, Sxx = spectrogram(x, fs=self.target_sr, nperseg=self.nperseg, noverlap=self.noverlap)\n",
    "        Sxx = np.log1p(Sxx)\n",
    "        return Sxx\n",
    "\n",
    "    def _pca_fallback(self, S: np.ndarray, dim: int = 128) -> np.ndarray:\n",
    "        if PCA is not None:\n",
    "            pca = PCA(n_components=min(dim, min(S.shape)-1))\n",
    "            X = S - S.mean(axis=0, keepdims=True)\n",
    "            try:\n",
    "                Z = pca.fit_transform(X)\n",
    "                feat = Z.mean(axis=0)\n",
    "            except Exception:\n",
    "                flat = S.flatten()\n",
    "                idx = np.linspace(0, flat.size - 1, dim).astype(int)\n",
    "                feat = flat[idx]\n",
    "            if feat.size < dim:\n",
    "                tmp = np.zeros(dim, dtype=np.float32)\n",
    "                tmp[:feat.size] = feat.astype(np.float32)\n",
    "                return tmp\n",
    "            return feat[:dim].astype(np.float32)\n",
    "        else:\n",
    "            flat = S.flatten()\n",
    "            if flat.size > dim:\n",
    "                idx = np.linspace(0, flat.size - 1, dim).astype(int)\n",
    "                return flat[idx].astype(np.float32)\n",
    "            else:\n",
    "                out = np.zeros(dim, dtype=np.float32)\n",
    "                out[:flat.size] = flat.astype(np.float32)\n",
    "                return out\n",
    "\n",
    "    def extract(self, x: np.ndarray, sr: int) -> Dict[str, Any]:\n",
    "        S = self.compute_spectrogram(x, sr)\n",
    "        audio_emb = self._pca_fallback(S, dim=128)\n",
    "        prosody = {\n",
    "            \"rms\": float(rms_energy(x)),\n",
    "            \"zcr\": float(zcr(x)),\n",
    "        }\n",
    "        return {\n",
    "            \"embedding\": audio_emb,\n",
    "            \"embedding_source\": \"PCA-fallback\",\n",
    "            \"spectrogram\": S,\n",
    "            \"spectrogram_shape\": S.shape,\n",
    "            \"prosody\": prosody,\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class TextEmbedder:\n",
    "    def embed(self, text: str) -> Dict[str, Any]:\n",
    "        vocab = [\n",
    "            \"good\",\"great\",\"excellent\",\"happy\",\"satisfied\",\"love\",\"amazing\",\"nice\",\"pleasant\",\"delight\",\n",
    "            \"bad\",\"terrible\",\"awful\",\"angry\",\"upset\",\"hate\",\"disappointed\",\"poor\",\"rude\",\"horrible\"\n",
    "        ]\n",
    "        if TfidfVectorizer is not None:\n",
    "            vec = TfidfVectorizer(vocabulary=vocab)\n",
    "            X = vec.fit_transform([text]).toarray().squeeze().astype(np.float32)\n",
    "        else:\n",
    "            toks = [t.strip(\".,!?\").lower() for t in text.split()]\n",
    "            X = np.array([toks.count(w) for w in vocab], dtype=np.float32)\n",
    "        return {\"embedding\": X, \"embedding_source\": \"TFIDF-lexicon-fallback\"}\n",
    "\n",
    "@dataclass\n",
    "class SentimentHead:\n",
    "    def predict(self, audio_emb: np.ndarray, text_emb: np.ndarray, prosody: Dict[str, float], text: str) -> Dict[str, Any]:\n",
    "        pos_words = {\"good\",\"great\",\"excellent\",\"happy\",\"satisfied\",\"love\",\"amazing\",\"nice\",\"pleasant\",\"delight\"}\n",
    "        neg_words = {\"bad\",\"terrible\",\"awful\",\"angry\",\"upset\",\"hate\",\"disappointed\",\"poor\",\"rude\",\"horrible\"}\n",
    "        toks = [t.strip(\".,!?\").lower() for t in text.split()]\n",
    "        pos = sum(w in pos_words for w in toks)\n",
    "        neg = sum(w in neg_words for w in toks)\n",
    "        text_score = (pos - neg) / (len(toks) + 1e-6)\n",
    "        rms = prosody.get(\"rms\", 0.0)\n",
    "        zc = prosody.get(\"zcr\", 0.0)\n",
    "        rms_n = normalize_minmax(rms, 0.0, 0.2)\n",
    "        zc_n = normalize_minmax(zc, 0.0, 0.2)\n",
    "        arousal = (rms_n + zc_n) / 2.0\n",
    "        audio_score = 1.0 - arousal\n",
    "        fused = 0.7 * text_score + 0.3 * (audio_score * 2 - 1)\n",
    "        prob_pos = 1 / (1 + np.exp(-3 * fused))\n",
    "        label = \"positive\" if prob_pos >= 0.5 else \"negative\"\n",
    "        return {\n",
    "            \"text_score\": float(text_score),\n",
    "            \"audio_score\": float(audio_score),\n",
    "            \"fused_score\": float(fused),\n",
    "            \"prob_positive\": float(prob_pos),\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "def generate_sine_speech_like(duration_s=2.0, sr=16000, f0=200.0, noise=0.01):\n",
    "    t = np.linspace(0, duration_s, int(sr*duration_s), endpoint=False)\n",
    "    am = 0.5 * (1 + np.sin(2*np.pi*2*t))\n",
    "    x = 0.3 * am * np.sin(2*np.pi*f0*t)\n",
    "    x += noise * np.random.randn(len(t))\n",
    "    return x.astype(np.float32), sr\n",
    "\n",
    "def run_pipeline(manual_transcript: Optional[str]=None) -> Dict[str, Any]:\n",
    "    x, sr = generate_sine_speech_like()\n",
    "    afe = AudioFeatureExtractor()\n",
    "    aout = afe.extract(x, sr)\n",
    "    if manual_transcript is None:\n",
    "        manual_transcript = \"I am very happy with the service, it was excellent and the staff was nice.\"\n",
    "    text = manual_transcript\n",
    "    te = TextEmbedder()\n",
    "    tout = te.embed(text)\n",
    "    head = SentimentHead()\n",
    "    pred = head.predict(aout[\"embedding\"], tout[\"embedding\"], aout[\"prosody\"], text)\n",
    "    result = {\n",
    "        \"audio_source\": \"synthetic\",\n",
    "        \"audio_embedding_source\": aout[\"embedding_source\"],\n",
    "        \"spectrogram_shape\": aout[\"spectrogram_shape\"],\n",
    "        \"prosody\": aout[\"prosody\"],\n",
    "        \"text_embedding_source\": tout.get(\"embedding_source\", \"unknown\"),\n",
    "        \"prediction\": pred,\n",
    "        \"transcript\": text\n",
    "    }\n",
    "    out_path = \"/mnt/data/pipeline_output.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    print(\"Saved pipeline outputs to:\", out_path)\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "    S = aout[\"spectrogram\"]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.imshow(S, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.colorbar(label=\"Log Power\")\n",
    "    plt.title(\"Spectrogram\")\n",
    "    plt.xlabel(\"Time frames\")\n",
    "    plt.ylabel(\"Frequency bins\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.bar([\"Negative\",\"Positive\"], [1-pred[\"prob_positive\"], pred[\"prob_positive\"]], color=[\"red\",\"green\"])\n",
    "    plt.title(f\"Sentiment Prediction: {pred['label'].upper()}\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "    return result\n",
    "\n",
    "outputs = run_pipeline()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
